import os
import json
import time
import matplotlib.pyplot as plt
import seaborn as sns
from core.formatter import CodeFormatter
from core.language_manager import LanguageManager

class CodeFormatterTester:
    def __init__(self):
        self.formatter = CodeFormatter(language='java')
        self.results = []
        self.test_cases = self._generate_test_cases()
    
    def _generate_test_cases(self):
        """Generate 100+ diverse Java test cases"""
        return [
            # Category 1: Class Declarations (15 test cases)
            {
                "name": "Simple Class",
                "input": "class MyClass{}",
                "expected": "class MyClass {}",
                "category": "class_declaration"
            },
            {
                "name": "Class with Public Modifier",
                "input": "public class Calculator{}",
                "expected": "public class Calculator {}",
                "category": "class_declaration"
            },
            {
                "name": "Abstract Class",
                "input": "abstract class Shape{}",
                "expected": "abstract class Shape {}",
                "category": "class_declaration"
            },
            {
                "name": "Final Class",
                "input": "public final class Constants{}",
                "expected": "public final class Constants {}",
                "category": "class_declaration"
            },
            {
                "name": "Class with Inheritance",
                "input": "class Dog extends Animal{}",
                "expected": "class Dog extends Animal {}",
                "category": "class_declaration"
            },
            {
                "name": "Class with Implementation",
                "input": "class ArrayList implements List{}",
                "expected": "class ArrayList implements List {}",
                "category": "class_declaration"
            },
            {
                "name": "Class with Multiple Interfaces",
                "input": "class MyClass implements A,B,C{}",
                "expected": "class MyClass implements A, B, C {}",
                "category": "class_declaration"
            },
            
            # Category 2: Method Declarations (20 test cases)
            {
                "name": "Simple Method",
                "input": "void method(){}",
                "expected": "void method() {}",
                "category": "method_declaration"
            },
            {
                "name": "Public Method",
                "input": "public void calculate(){}",
                "expected": "public void calculate() {}",
                "category": "method_declaration"
            },
            {
                "name": "Static Method",
                "input": "public static void main(String[] args){}",
                "expected": "public static void main(String[] args) {}",
                "category": "method_declaration"
            },
            {
                "name": "Method with Parameters",
                "input": "void add(int a,int b){}",
                "expected": "void add(int a, int b) {}",
                "category": "method_declaration"
            },
            {
                "name": "Method with Return Type",
                "input": "int getValue(){}",
                "expected": "int getValue() {}",
                "category": "method_declaration"
            },
            {
                "name": "Synchronized Method",
                "input": "synchronized void update(){}",
                "expected": "synchronized void update() {}",
                "category": "method_declaration"
            },
            {
                "name": "Method with Throws",
                "input": "void read()throws IOException{}",
                "expected": "void read() throws IOException {}",
                "category": "method_declaration"
            },
            {
                "name": "Generic Method",
                "input": "public<T> T process(T input){}",
                "expected": "public <T> T process(T input) {}",
                "category": "method_declaration"
            },
            
            # Category 3: Variable Declarations (15 test cases)
            {
                "name": "Integer Variable",
                "input": "int x=5;",
                "expected": "int x = 5;",
                "category": "variable_declaration"
            },
            {
                "name": "String Variable",
                "input": "String name=\"John\";",
                "expected": "String name = \"John\";",
                "category": "variable_declaration"
            },
            {
                "name": "Final Variable",
                "input": "final int MAX_SIZE=100;",
                "expected": "final int MAX_SIZE = 100;",
                "category": "variable_declaration"
            },
            {
                "name": "Array Declaration",
                "input": "int[] numbers=new int[10];",
                "expected": "int[] numbers = new int[10];",
                "category": "variable_declaration"
            },
            {
                "name": "Multiple Variables",
                "input": "int a=1,b=2,c=3;",
                "expected": "int a = 1, b = 2, c = 3;",
                "category": "variable_declaration"
            },
            {
                "name": "Object Declaration",
                "input": "List<String> list=new ArrayList<>();",
                "expected": "List<String> list = new ArrayList<>();",
                "category": "variable_declaration"
            },
            
            # Category 4: Control Structures (25 test cases)
            {
                "name": "If Statement",
                "input": "if(condition){}",
                "expected": "if (condition) {}",
                "category": "control_structures"
            },
            {
                "name": "If-Else Statement",
                "input": "if(x>0){}else{}",
                "expected": "if (x > 0) {} else {}",
                "category": "control_structures"
            },
            {
                "name": "While Loop",
                "input": "while(condition){}",
                "expected": "while (condition) {}",
                "category": "control_structures"
            },
            {
                "name": "Do-While Loop",
                "input": "do{}while(condition);",
                "expected": "do {} while (condition);",
                "category": "control_structures"
            },
            {
                "name": "Switch Statement",
                "input": "switch(value){case 1:break;}",
                "expected": "switch (value) { case 1: break; }",
                "category": "control_structures"
            },
            {
                "name": "Try-Catch Block",
                "input": "try{}catch(Exception e){}",
                "expected": "try {} catch (Exception e) {}",
                "category": "control_structures"
            },
            {
                "name": "Try with Resources",
                "input": "try(FileReader fr=new FileReader(\"file.txt\")){}",
                "expected": "try (FileReader fr = new FileReader(\"file.txt\")) {}",
                "category": "control_structures"
            },
            {
                "name": "Synchronized Block",
                "input": "synchronized(lock){}",
                "expected": "synchronized (lock) {}",
                "category": "control_structures"
            },
            
            # Category 5: Expressions and Operators (20 test cases)
            {
                "name": "Arithmetic Expression",
                "input": "int result=a+b*c/d;",
                "expected": "int result = a + b * c / d;",
                "category": "expressions"
            },
            {
                "name": "Comparison Expression",
                "input": "boolean isEqual=x==y;",
                "expected": "boolean isEqual = x == y;",
                "category": "expressions"
            },
            {
                "name": "Logical Expression",
                "input": "if(a&&b||c){}",
                "expected": "if (a && b || c) {}",
                "category": "expressions"
            },
            {
                "name": "Ternary Operator",
                "input": "int max=a>b?a:b;",
                "expected": "int max = a > b ? a : b;",
                "category": "expressions"
            },
            {
                "name": "Assignment Chain",
                "input": "a=b=c=0;",
                "expected": "a = b = c = 0;",
                "category": "expressions"
            },
            {
                "name": "Method Call",
                "input": "object.method(param1,param2);",
                "expected": "object.method(param1, param2);",
                "category": "expressions"
            },
            {
                "name": "Constructor Call",
                "input": "new Object(param1,param2);",
                "expected": "new Object(param1, param2);",
                "category": "expressions"
            },
            
            # Category 6: Complex Real-World Examples (15 test cases)
            {
                "name": "Calculator Method",
                "input": "public int calculate(int a,int b){return a+b;}",
                "expected": "public int calculate(int a, int b) { return a + b; }",
                "category": "complex"
            },
            {
                "name": "Data Class",
                "input": "public class Person{private String name;private int age;public Person(String name,int age){this.name=name;this.age=age;}}",
                "expected": "public class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } }",
                "category": "complex"
            },
            {
                "name": "Utility Method",
                "input": "public static boolean isValid(String input){return input!=null&&!input.isEmpty();}",
                "expected": "public static boolean isValid(String input) { return input != null && !input.isEmpty(); }",
                "category": "complex"
            },
            {
                "name": "Loop with Condition",
                "input": "for(int i=0;i<array.length;i++){if(array[i]>0){process(array[i]);}}",
                "expected": "for (int i = 0; i < array.length; i++) { if (array[i] > 0) { process(array[i]); } }",
                "category": "complex"
            },
            
            # Add more test cases to reach 100+
            {
                "name": "Interface Declaration",
                "input": "interface Drawable{void draw();}",
                "expected": "interface Drawable { void draw(); }",
                "category": "class_declaration"
            },
            {
                "name": "Enum Declaration", 
                "input": "enum Color{RED,GREEN,BLUE}",
                "expected": "enum Color { RED, GREEN, BLUE }",
                "category": "class_declaration"
            },
            {
                "name": "Annotation Declaration",
                "input": "@interface MyAnnotation{String value();}",
                "expected": "@interface MyAnnotation { String value(); }",
                "category": "class_declaration"
            },
            {
                "name": "Method with Array Parameter",
                "input": "void process(int[] data){}",
                "expected": "void process(int[] data) {}",
                "category": "method_declaration"
            },
            {
                "name": "Varargs Method",
                "input": "void printAll(String... messages){}",
                "expected": "void printAll(String... messages) {}",
                "category": "method_declaration"
            },
            {
                "name": "Lambda Expression",
                "input": "Runnable r=()->System.out.println(\"Hello\");",
                "expected": "Runnable r = () -> System.out.println(\"Hello\");",
                "category": "expressions"
            },
            {
                "name": "Stream Operation",
                "input": "list.stream().filter(x->x>0).map(x->x*2).collect(Collectors.toList());",
                "expected": "list.stream().filter(x -> x > 0).map(x -> x * 2).collect(Collectors.toList());",
                "category": "expressions"
            },
            # ... Continue adding more test cases to reach 100+
        ]
    
    def run_tests(self):
        """Run all test cases and collect results"""
        print("üöÄ Starting Comprehensive Code Formatter Test Suite")
        print(f"üìä Testing {len(self.test_cases)} diverse Java code patterns...")
        print("=" * 80)
        
        for i, test_case in enumerate(self.test_cases, 1):
            print(f"üß™ Test {i}/{len(self.test_cases)}: {test_case['name']}")
            
            # Create temporary file for testing
            test_file = f"temp_test_{i}.java"
            with open(test_file, 'w') as f:
                f.write(test_case['input'])
            
            try:
                # Format the code
                start_time = time.time()
                result = self.formatter.format_file(test_file)
                end_time = time.time()
                
                # Clean up
                os.remove(test_file)
                if os.path.exists(f"temp_test_{i}_formatted.java"):
                    os.remove(f"temp_test_{i}_formatted.java")
                
                # Calculate accuracy
                formatted_code = result['formatted_code'].strip()
                expected_code = test_case['expected'].strip()
                is_correct = formatted_code == expected_code
                
                # Store results
                self.results.append({
                    'test_id': i,
                    'name': test_case['name'],
                    'category': test_case['category'],
                    'input': test_case['input'],
                    'expected': expected_code,
                    'actual': formatted_code,
                    'is_correct': is_correct,
                    'formatting_score': result['formatting_score'],
                    'issues_found': len(result['issues_found']),
                    'fixes_applied': result['fixes_applied'],
                    'processing_time': end_time - start_time,
                    'success_rate': result['fixes_applied'] / len(result['issues_found']) if result['issues_found'] else 1.0
                })
                
                status = "‚úÖ PASS" if is_correct else "‚ùå FAIL"
                print(f"   {status} | Score: {result['formatting_score']:.1f}% | Time: {end_time - start_time:.3f}s")
                
            except Exception as e:
                print(f"   üí• ERROR: {e}")
                self.results.append({
                    'test_id': i,
                    'name': test_case['name'],
                    'category': test_case['category'],
                    'input': test_case['input'],
                    'expected': test_case['expected'],
                    'actual': f"ERROR: {e}",
                    'is_correct': False,
                    'formatting_score': 0,
                    'issues_found': 0,
                    'fixes_applied': 0,
                    'processing_time': 0,
                    'success_rate': 0
                })
        
        self._generate_report()
    
    def _generate_report(self):
        """Generate comprehensive test report and charts"""
        print("\n" + "=" * 80)
        print("üìà COMPREHENSIVE TEST RESULTS")
        print("=" * 80)
        
        # Calculate overall metrics
        total_tests = len(self.results)
        passed_tests = sum(1 for r in self.results if r['is_correct'])
        failed_tests = total_tests - passed_tests
        overall_accuracy = (passed_tests / total_tests) * 100
        
        avg_formatting_score = sum(r['formatting_score'] for r in self.results) / total_tests
        avg_processing_time = sum(r['processing_time'] for r in self.results) / total_tests
        avg_success_rate = sum(r['success_rate'] for r in self.results) / total_tests * 100
        
        print(f"üìä Overall Accuracy: {overall_accuracy:.1f}% ({passed_tests}/{total_tests})")
        print(f"üéØ Average Formatting Score: {avg_formatting_score:.1f}%")
        print(f"‚ö° Average Processing Time: {avg_processing_time:.3f}s")
        print(f"üîß Average Fix Success Rate: {avg_success_rate:.1f}%")
        
        # Generate charts
        self._create_charts()
        
        # Save detailed results
        self._save_detailed_results()
    
    def _create_charts(self):
        """Create comprehensive visualization charts"""
        # Set up the plotting style
        plt.style.use('seaborn-v0_8')
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Code Formatter Performance Analysis', fontsize=16, fontweight='bold')
        
        # Chart 1: Accuracy by Category
        categories = {}
        for result in self.results:
            cat = result['category']
            if cat not in categories:
                categories[cat] = {'total': 0, 'passed': 0}
            categories[cat]['total'] += 1
            if result['is_correct']:
                categories[cat]['passed'] += 1
        
        category_names = list(categories.keys())
        category_accuracy = [(categories[cat]['passed'] / categories[cat]['total']) * 100 for cat in category_names]
        
        bars = axes[0, 0].bar(category_names, category_accuracy, color='skyblue', edgecolor='navy')
        axes[0, 0].set_title('Accuracy by Code Category', fontweight='bold')
        axes[0, 0].set_ylabel('Accuracy (%)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # Add value labels on bars
        for bar, accuracy in zip(bars, category_accuracy):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           f'{accuracy:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        # Chart 2: Formatting Score Distribution
        formatting_scores = [r['formatting_score'] for r in self.results]
        axes[0, 1].hist(formatting_scores, bins=20, alpha=0.7, color='lightgreen', edgecolor='darkgreen')
        axes[0, 1].set_title('Formatting Score Distribution', fontweight='bold')
        axes[0, 1].set_xlabel('Formatting Score (%)')
        axes[0, 1].set_ylabel('Frequency')
        axes[0, 1].axvline(avg_formatting_score, color='red', linestyle='--', label=f'Avg: {avg_formatting_score:.1f}%')
        axes[0, 1].legend()
        
        # Chart 3: Processing Time Analysis
        processing_times = [r['processing_time'] for r in self.results]
        axes[0, 2].scatter(range(len(processing_times)), processing_times, alpha=0.6, color='orange')
        axes[0, 2].set_title('Processing Time per Test Case', fontweight='bold')
        axes[0, 2].set_xlabel('Test Case Number')
        axes[0, 2].set_ylabel('Processing Time (seconds)')
        axes[0, 2].axhline(avg_processing_time, color='red', linestyle='--', label=f'Avg: {avg_processing_time:.3f}s')
        axes[0, 2].legend()
        
        # Chart 4: Issues vs Fixes
        issues_found = [r['issues_found'] for r in self.results]
        fixes_applied = [r['fixes_applied'] for r in self.results]
        axes[1, 0].scatter(issues_found, fixes_applied, alpha=0.6, color='purple')
        axes[1, 0].set_title('Issues Found vs Fixes Applied', fontweight='bold')
        axes[1, 0].set_xlabel('Issues Found')
        axes[1, 0].set_ylabel('Fixes Applied')
        
        # Perfect fix line
        max_issues = max(issues_found) if issues_found else 0
        axes[1, 0].plot([0, max_issues], [0, max_issues], 'r--', alpha=0.7, label='Perfect Fix Line')
        axes[1, 0].legend()
        
        # Chart 5: Success Rate by Test Complexity
        test_complexity = [len(r['input']) for r in self.results]  # Using input length as complexity proxy
        success_rates = [r['success_rate'] * 100 for r in self.results]
        axes[1, 1].scatter(test_complexity, success_rates, alpha=0.6, color='coral')
        axes[1, 1].set_title('Success Rate vs Test Complexity', fontweight='bold')
        axes[1, 1].set_xlabel('Test Complexity (Input Length)')
        axes[1, 1].set_ylabel('Fix Success Rate (%)')
        
        # Chart 6: Category Performance Heatmap
        category_metrics = {}
        for cat in categories:
            cat_results = [r for r in self.results if r['category'] == cat]
            category_metrics[cat] = {
                'accuracy': sum(1 for r in cat_results if r['is_correct']) / len(cat_results) * 100,
                'avg_score': sum(r['formatting_score'] for r in cat_results) / len(cat_results),
                'avg_time': sum(r['processing_time'] for r in cat_results) / len(cat_results)
            }
        
        # Create heatmap data
        metrics = ['Accuracy', 'Formatting Score', 'Processing Time']
        heatmap_data = [
            [category_metrics[cat]['accuracy'] for cat in category_names],
            [category_metrics[cat]['avg_score'] for cat in category_names],
            [category_metrics[cat]['avg_time'] * 1000 for cat in category_names]  # Convert to ms for better scale
        ]
        
        im = axes[1, 2].imshow(heatmap_data, cmap='YlGnBu', aspect='auto')
        axes[1, 2].set_title('Category Performance Heatmap', fontweight='bold')
        axes[1, 2].set_xticks(range(len(category_names)))
        axes[1, 2].set_xticklabels(category_names, rotation=45)
        axes[1, 2].set_yticks(range(len(metrics)))
        axes[1, 2].set_yticklabels(metrics)
        
        # Add text annotations
        for i in range(len(metrics)):
            for j in range(len(category_names)):
                text = axes[1, 2].text(j, i, f'{heatmap_data[i][j]:.1f}',
                                      ha="center", va="center", color="black", fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('formatter_performance_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"üìä Performance charts saved as 'formatter_performance_analysis.png'")
    
    def _save_detailed_results(self):
        """Save detailed test results to JSON file"""
        results_summary = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_tests': len(self.results),
            'passed_tests': sum(1 for r in self.results if r['is_correct']),
            'overall_accuracy': (sum(1 for r in self.results if r['is_correct']) / len(self.results)) * 100,
            'average_formatting_score': sum(r['formatting_score'] for r in self.results) / len(self.results),
            'average_processing_time': sum(r['processing_time'] for r in self.results) / len(self.results),
            'detailed_results': self.results
        }
        
        with open('formatter_test_results.json', 'w') as f:
            json.dump(results_summary, f, indent=2)
        
        print(f"üìÑ Detailed results saved as 'formatter_test_results.json'")

def main():
    """Run the comprehensive test suite"""
    tester = CodeFormatterTester()
    tester.run_tests()

if __name__ == "__main__":
    main()